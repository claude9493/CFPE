{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BetaRec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWIumqUKFJxbQLwBo0o5lL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claude9493/DSAA5002/blob/main/notebook/BetaRec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoMa4IzK6Qrn"
      },
      "source": [
        "!git clone https://github.com/claude9493/dsaa5002.git\n",
        "!mv ./dsaa5002/dataset/ ./\n",
        "!mv ./dsaa5002/utils/ ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_z1xJHo6WLt"
      },
      "source": [
        "%%time\n",
        "\n",
        "from utils.utils import create_dataset, Trainer\n",
        "# from layer.layer import Embedding, FeaturesEmbedding, EmbeddingsInteraction, MultiLayerPerceptron\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Training on [{}].'.format(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5mq1ihz6XqM"
      },
      "source": [
        "%%time\n",
        "SAMPLE_NUM = 10000\n",
        "task = 'regression'  # 'classification'\n",
        "dataset = create_dataset('movielens', sample_num=SAMPLE_NUM, task=task, device=device)\n",
        "field_dims, (train_X, train_y), (valid_X, valid_y), (test_X, test_y) = dataset.train_valid_test_split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTsF5YWK6ZjW"
      },
      "source": [
        "class EE_Loss:\n",
        "    def __init__(self, model, reg_biase=0.005, reg_lambda=0.005):\n",
        "        self.reg_biase = reg_biase\n",
        "        self.reg_lambda = reg_lambda\n",
        "        self.model = model\n",
        "\n",
        "    def __call__(self, pred, target):\n",
        "        loss = (1-self.reg_biase - self.reg_lambda) * nn.MSELoss()(pred, target)\n",
        "        loss += self.reg_biase * self.model.loss[0]\n",
        "        loss += self.reg_lambda * self.model.loss[1]\n",
        "        return loss\n",
        "\n",
        "\n",
        "class EuclideanEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self, field_dims, embed_dim=4):\n",
        "        super(EuclideanEmbedding, self).__init__()\n",
        "        n_users, n_movies = field_dims[0], field_dims[1]\n",
        "        self.Bu = nn.Parameter(torch.randn(n_users), requires_grad=True)\n",
        "        self.Bm = nn.Parameter(torch.randn(n_movies), requires_grad=True)\n",
        "        self.u = nn.Embedding(n_users, embed_dim)\n",
        "        self.m = nn.Embedding(n_movies, embed_dim)\n",
        "        \n",
        "        self.u.weight.data.uniform_(0, 0.05)\n",
        "        self.m.weight.data.uniform_(0, 0.05)\n",
        "        self.loss = [0,0]\n",
        "\n",
        "        \n",
        "    def forward(self, x, global_mean=0):\n",
        "        users, movies = x[:,0], x[:,1]\n",
        "        u, m = self.u(users), self.m(movies)\n",
        "        Bu, Bm = self.Bu[users], self.Bm[movies]\n",
        "        difference = u-m\n",
        "        output = global_mean + Bu + Bm - torch.linalg.norm(torch.mul(difference, difference))\n",
        "        \n",
        "        self.loss[0] = torch.norm(Bu) + torch.norm(Bm)\n",
        "        self.loss[1] = torch.norm(u) + torch.norm(m)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpXIAm7E6pb-"
      },
      "source": [
        "%%time\n",
        "\n",
        "EMBEDDING_DIM = 8\n",
        "LEARNING_RATE = 1e-4\n",
        "REGULARIZATION = 1e-6\n",
        "BATCH_SIZE = 1024\n",
        "EPOCH = 5000\n",
        "TRIAL = 1000\n",
        "\n",
        "ee = EuclideanEmbedding(field_dims, EMBEDDING_DIM).to(device)\n",
        "\n",
        "optimizer = optim.Adam(ee.parameters(), lr=LEARNING_RATE, weight_decay=REGULARIZATION)\n",
        "# criterion = nn.BCELoss()\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = EE_Loss(model=ee)\n",
        "\n",
        "trainer = Trainer(ee, optimizer, criterion, BATCH_SIZE, task=task)\n",
        "trainer.train(train_X, train_y, epoch=EPOCH, trials=TRIAL, valid_X=valid_X, valid_y=valid_y)\n",
        "test_loss, test_metric = trainer.test(test_X, test_y)\n",
        "print('test_loss:  {:.5f} | test_metric:  {:.5f}'.format(test_loss, test_metric))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}