{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BetaRec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdfxjitvXkZBHhKcPhQwVM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claude9493/DSAA5002/blob/main/notebook/BetaRec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoMa4IzK6Qrn",
        "outputId": "04bbb927-838a-40bd-966d-56e8916e400e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/claude9493/dsaa5002.git\n",
        "!mv ./dsaa5002/dataset/ ./\n",
        "!mv ./dsaa5002/utils/ ./"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dsaa5002'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 34 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_z1xJHo6WLt",
        "outputId": "5a00be6b-03de-4fb1-956b-a357de703629",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "from utils.utils import create_dataset, Trainer\n",
        "# from layer.layer import Embedding, FeaturesEmbedding, EmbeddingsInteraction, MultiLayerPerceptron\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Training on [{}].'.format(device))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on [cpu].\n",
            "CPU times: user 1.02 s, sys: 1.06 s, total: 2.08 s\n",
            "Wall time: 27.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5mq1ihz6XqM",
        "outputId": "8a8e5cb5-3928-4c30-b032-9ad11a6adcb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "SAMPLE_NUM = 10000\n",
        "task = 'regression'  # 'classification'\n",
        "dataset = create_dataset('movielens', sample_num=SAMPLE_NUM, task=task, device=device)\n",
        "field_dims, (train_X, train_y), (valid_X, valid_y), (test_X, test_y) = dataset.train_valid_test_split()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17.3 ms, sys: 2.41 ms, total: 19.7 ms\n",
            "Wall time: 79.4 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTsF5YWK6ZjW"
      },
      "source": [
        "class Beta_Loss:\n",
        "    def __init__(self, model, reg_biase=0.005, reg_lambda=0.005):\n",
        "        self.reg_biase = reg_biase\n",
        "        self.reg_lambda = reg_lambda\n",
        "        self.model = model\n",
        "\n",
        "    def __call__(self, pred, target):\n",
        "        loss = (1-self.reg_biase - self.reg_lambda) * nn.MSELoss()(pred, target)\n",
        "        loss += self.reg_biase * self.model.loss[0]\n",
        "        loss += self.reg_lambda * self.model.loss[1]\n",
        "        return loss\n",
        "\n",
        "\n",
        "class BetaRecommendation(nn.Module):\n",
        "\n",
        "    def __init__(self, field_dims, embed_dim=4):\n",
        "        super(BetaRecommendation, self).__init__()\n",
        "        n_users, n_movies = field_dims[0], field_dims[1]\n",
        "\n",
        "        self.Bu = nn.Parameter(torch.randn(n_users), requires_grad=True)\n",
        "        self.Bm = nn.Parameter(torch.randn(n_movies), requires_grad=True)\n",
        "\n",
        "        self.u = nn.Embedding(n_users, embed_dim)\n",
        "        self.m = nn.Embedding(n_movies, embed_dim)\n",
        "        \n",
        "        self.u.weight.data.uniform_(0, 0.05)\n",
        "        self.m.weight.data.uniform_(0, 0.05)\n",
        "        self.loss = [0,0]\n",
        "\n",
        "        \n",
        "    def forward(self, x, global_mean=0):\n",
        "        users, movies = x[:,0], x[:,1]\n",
        "        u, m = self.u(users), self.m(movies)\n",
        "        Bu, Bm = self.Bu[users], self.Bm[movies]\n",
        "        alpha_u, beta_u = torch.chunk(u, 2, dim=-1)\n",
        "        alpha_m, beta_m = torch.chunk(m, 2, dim=-1)\n",
        "\n",
        "        u_dist = torch.distributions.beta.Beta(alpha_u, beta_u)\n",
        "        m_dist = touch.distributions.beta.Beta(alpha_m, beta_m)\n",
        "\n",
        "        distance = self.distance(u_dist, m_dist)\n",
        "    \n",
        "        output = global_mean + Bu + Bm - distance\n",
        "        \n",
        "        self.loss[0] = torch.norm(Bu) + torch.norm(Bm)\n",
        "        # self.loss[1] = torch.norm(u) + torch.norm(m)\n",
        "        return output\n",
        "      \n",
        "    def distance(self, u_dist, m_dist):\n",
        "      return torch.norm(math.pi/2.0 * \n",
        "                        torch.atan(\n",
        "                            torch.distributions.kl.kl_divergence(\n",
        "                                u_dist, m_dist)), \n",
        "                        p=1, dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpXIAm7E6pb-"
      },
      "source": [
        "%%time\n",
        "\n",
        "EMBEDDING_DIM = 8\n",
        "LEARNING_RATE = 1e-4\n",
        "REGULARIZATION = 1e-6\n",
        "BATCH_SIZE = 1024\n",
        "EPOCH = 5000\n",
        "TRIAL = 1000\n",
        "\n",
        "br = BetaRecommendation(field_dims, EMBEDDING_DIM).to(device)\n",
        "\n",
        "optimizer = optim.Adam(br.parameters(), lr=LEARNING_RATE, weight_decay=REGULARIZATION)\n",
        "# criterion = nn.BCELoss()\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = EE_Loss(model=br)\n",
        "\n",
        "trainer = Trainer(br, optimizer, criterion, BATCH_SIZE, task=task)\n",
        "trainer.train(train_X, train_y, epoch=EPOCH, trials=TRIAL, valid_X=valid_X, valid_y=valid_y)\n",
        "test_loss, test_metric = trainer.test(test_X, test_y)\n",
        "print('test_loss:  {:.5f} | test_metric:  {:.5f}'.format(test_loss, test_metric))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}