{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BetaRec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOg7nfsAv/HfkZHULDKM/zQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claude9493/DSAA5002/blob/main/notebook/BetaRec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoMa4IzK6Qrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2872ddd1-c3df-40f2-bae4-def8578dc1c7"
      },
      "source": [
        "!git clone https://github.com/claude9493/dsaa5002.git\n",
        "!mv ./dsaa5002/dataset/ ./\n",
        "!mv ./dsaa5002/utils/ ./"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dsaa5002'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 60 (delta 16), reused 4 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (60/60), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMmsKramoCol",
        "outputId": "8920338a-d920-44ba-b32f-c18902ea98e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install geomloss"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geomloss\n",
            "  Downloading geomloss-0.2.4-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from geomloss) (1.19.5)\n",
            "Installing collected packages: geomloss\n",
            "Successfully installed geomloss-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_z1xJHo6WLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e050cee-a5de-4ea5-acfb-e142e683e12d"
      },
      "source": [
        "%%time\n",
        "\n",
        "from utils.utils import create_dataset, Trainer\n",
        "# from layer.layer import Embedding, FeaturesEmbedding, EmbeddingsInteraction, MultiLayerPerceptron\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from geomloss import SamplesLoss\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Training on [{}].'.format(device))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on [cuda:0].\n",
            "CPU times: user 1.04 s, sys: 772 ms, total: 1.81 s\n",
            "Wall time: 6.35 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5mq1ihz6XqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4e35d5-fb56-4cdd-8db8-b3aa295280c4"
      },
      "source": [
        "%%time\n",
        "SAMPLE_NUM = 10000\n",
        "task = 'regression'  # 'classification'\n",
        "dataset = create_dataset('movielens', sample_num=SAMPLE_NUM, task=task, device=device)\n",
        "field_dims, (train_X, train_y), (valid_X, valid_y), (test_X, test_y) = dataset.train_valid_test_split()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.75 s, sys: 1.03 s, total: 2.78 s\n",
            "Wall time: 10 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnCcw77aRwEX"
      },
      "source": [
        "# train_iterator = SingledirectionalOneShotIterator(DataLoader(\n",
        "#     TensorDataset(train_X, train_y),\n",
        "#     # TrainDataset(train_path_queries, nentity, nrelation, args.negative_sample_size, train_answers),\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     shuffle=True\n",
        "#     # num_workers=args.cpu_num\n",
        "#     # collate_fn=TrainDataset.collate_fn\n",
        "# ))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NImmD9NJd0V2",
        "outputId": "0cfe92d6-6c89-46c6-9d7f-1ba7a3275207",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sl = SamplesLoss(loss=\"sinkhorn\", blur=0.001)\n",
        "params = [(.5, .5), (5, 1), (1,3), (2,2), (2,5)]\n",
        "\n",
        "def w_dist(p1, p2):\n",
        "  x = torch.arange(0.01, 1.01, 0.05).view(-1,1)\n",
        "  d1 = torch.distributions.beta.Beta(*p1)\n",
        "  d2 = torch.distributions.beta.Beta(*p2)\n",
        "  u_ref = torch.exp(d1.log_prob(x))\n",
        "  m_ref = torch.exp(d2.log_prob(x))\n",
        "  return sl.forward(u_ref, m_ref)\n",
        "\n",
        "import itertools\n",
        "for params in itertools.combinations(params, 2):\n",
        "  print(f\"{params}: {w_dist(params[0], params[1]):.4}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((0.5, 0.5), (5, 1)): 0.2511\n",
            "((0.5, 0.5), (1, 3)): 0.1057\n",
            "((0.5, 0.5), (2, 2)): 0.06067\n",
            "((0.5, 0.5), (2, 5)): 0.1014\n",
            "((5, 1), (1, 3)): 0.0807\n",
            "((5, 1), (2, 2)): 0.3799\n",
            "((5, 1), (2, 5)): 0.08919\n",
            "((1, 3), (2, 2)): 0.1298\n",
            "((1, 3), (2, 5)): 0.004072\n",
            "((2, 2), (2, 5)): 0.1171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZywiMRRGrEQq"
      },
      "source": [
        "class SingledirectionalOneShotIterator(object):\n",
        "    def __init__(self, dataloader):\n",
        "        self.iterator = self.one_shot_iterator(dataloader)\n",
        "        self.step = 0\n",
        "        \n",
        "    def __next__(self):\n",
        "        self.step += 1\n",
        "        data = next(self.iterator)\n",
        "        return data\n",
        "    \n",
        "    @staticmethod\n",
        "    def one_shot_iterator(dataloader):\n",
        "        while True:\n",
        "            for data in dataloader:\n",
        "                yield data\n",
        "\n",
        "class Beta_Loss:\n",
        "    def __init__(self, model, reg_biase=0.005, reg_lambda=0.005):\n",
        "        self.reg_biase = reg_biase\n",
        "        self.reg_lambda = reg_lambda\n",
        "        self.model = model\n",
        "\n",
        "    def __call__(self, pred, target):\n",
        "        loss = (1-self.reg_biase) * nn.MSELoss()(pred.view(-1,1), target)\n",
        "        loss += self.reg_biase * self.model.loss[0]\n",
        "        # loss += self.reg_lambda * self.model.loss[1]\n",
        "        # loss = nn.MSELoss(reduction='sum')(pred.view(-1,1), target)\n",
        "        loss = torch.nan_to_num(loss)\n",
        "        return loss\n",
        "\n",
        "class Regularizer():\n",
        "    def __init__(self, base_add, min_val, max_val):\n",
        "        self.base_add = base_add\n",
        "        self.min_val = min_val\n",
        "        self.max_val = max_val\n",
        "\n",
        "    def __call__(self, entity_embedding):\n",
        "        return torch.clamp(entity_embedding + self.base_add, self.min_val, self.max_val)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTsF5YWK6ZjW"
      },
      "source": [
        "class BetaRecommendation(nn.Module):\n",
        "\n",
        "    def __init__(self, field_dims, embed_dim=4, **kwargs):\n",
        "        super(BetaRecommendation, self).__init__()\n",
        "        n_users, n_movies = field_dims[0], field_dims[1]\n",
        "\n",
        "        self.gamma = nn.Parameter(\n",
        "            torch.Tensor([kwargs.get('gamma', 12)]), \n",
        "            requires_grad=False)\n",
        "        self.lb = kwargs.get('lb', 0.05)\n",
        "        self.ub = kwargs.get('ub', 1e9)\n",
        "\n",
        "        self.Bu = nn.Parameter(torch.randn(n_users), requires_grad=True)\n",
        "        self.Bm = nn.Parameter(torch.randn(n_movies), requires_grad=True)\n",
        "\n",
        "        self.u = nn.Embedding(n_users, embed_dim * 2)\n",
        "        # self.u = nn.Parameter(torch.zeros(n_users, embed_dim * 2))\n",
        "        self.m = nn.Embedding(n_movies, embed_dim * 2)\n",
        "        # self.m = nn.Parameter(torch.zeros(n_movies, embed_dim * 2))\n",
        "        \n",
        "        self.u.weight.data.uniform_(self.lb, self.ub)\n",
        "        self.m.weight.data.uniform_(self.lb, self.ub)\n",
        "        \n",
        "        self.regularizer = Regularizer(1, self.lb, self.ub)\n",
        "        self.loss = [0,0]\n",
        "\n",
        "        self.sample_loss = SamplesLoss(loss=\"sinkhorn\", blur=0.001)\n",
        "\n",
        "        \n",
        "    def forward(self, x, global_mean=0):\n",
        "      # Predict rating\n",
        "        users, movies = x[:,0], x[:,1]\n",
        "        u, m = self.u(users), self.m(movies)\n",
        "        Bu, Bm = self.Bu[users], self.Bm[movies]\n",
        "        u[torch.isnan(u)] = 0.05\n",
        "        m[torch.isnan(m)] = 0.05\n",
        "\n",
        "        alpha_u, beta_u = torch.chunk(self.regularizer(u), 2, dim=-1)\n",
        "        alpha_m, beta_m = torch.chunk(self.regularizer(m), 2, dim=-1)\n",
        "\n",
        "        u_dist = torch.distributions.beta.Beta(alpha_u, beta_u)\n",
        "        m_dist = torch.distributions.beta.Beta(alpha_m, beta_m)\n",
        "\n",
        "        # distance = self.distance(u_dist, m_dist)\n",
        "        distance = self.Wasserstein_distance(u_dist, m_dist)\n",
        "    \n",
        "        output = Bu + Bm - distance\n",
        "        \n",
        "        self.loss[0] = torch.norm(Bu) + torch.norm(Bm)\n",
        "        return output\n",
        "      \n",
        "    def KL_Distance(self, u_dist, m_dist):\n",
        "      # return torch.norm(torch.distributions.kl.kl_divergence(u_dist, m_dist), p=1, dim=-1)\n",
        "      \n",
        "      # print([u_dist, m_dist, \n",
        "            #  torch.norm(torch.nan_to_num(torch.log(torch.distributions.kl.kl_divergence(u_dist, m_dist)), \n",
        "                                        #  nan=1.0, posinf=1.0), p=1, dim=-1)])\n",
        "\n",
        "      return torch.nan_to_num(self.gamma - torch.norm(torch.nan_to_num(torch.log(torch.distributions.kl.kl_divergence(u_dist, m_dist)), \n",
        "                                                                       nan=1, posinf=1), p=1, dim=-1))\n",
        "      # return torch.norm(torch.pi/2.0 * torch.atan(torch.distributions.kl.kl_divergence(u_dist, m_dist)), p=1, dim=-1)\n",
        "\n",
        "    def Wasserstein_distance(self, u_dist, m_dist):\n",
        "      # Generate reference points\n",
        "      x = torch.arange(0.01, 1.01, 0.05).view(-1,1)\n",
        "      u_ref = torch.exp(u_dist.log_prob(x))\n",
        "      m_ref = torch.exp(m_dist.log_prob(x))\n",
        "      return torch.nan_to_num(torch.norm(self.sample_loss.forward(u_ref, m_ref), p=1, dim=-1))\n",
        "\n",
        "    #staticmethod\n",
        "    # def train_step(model, optimizer, train_iterator, args, step):\n",
        "    #   model.train()\n",
        "    #   optimizer.zero_grad()\n",
        "    #   x, y = next(train_iterator)\n",
        "    #   users, movies = x[:,0], x[:,1]\n",
        "\n",
        "    #   batch_queries_dict = collections.defaultdict(list)\n",
        "    #   batch_idxs_dict = collections.defaultdict(list)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpXIAm7E6pb-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "1a7e44fb-a446-402c-9a3b-4bf48bd23a7f"
      },
      "source": [
        "%%time\n",
        "\n",
        "EMBEDDING_DIM = 16\n",
        "LEARNING_RATE = 1e-4\n",
        "REGULARIZATION = 1e-6\n",
        "BATCH_SIZE = 1024\n",
        "EPOCH = 500\n",
        "TRIAL = 100\n",
        "\n",
        "br = BetaRecommendation(field_dims, EMBEDDING_DIM).to(device)\n",
        "\n",
        "optimizer = optim.Adam(br.parameters(), lr=LEARNING_RATE, weight_decay=REGULARIZATION)\n",
        "# criterion = nn.BCELoss()\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = Beta_Loss(model=br)\n",
        "\n",
        "trainer = Trainer(br, optimizer, criterion, BATCH_SIZE, task=task)\n",
        "trainer.train(train_X, train_y, epoch=EPOCH, trials=TRIAL, valid_X=valid_X, valid_y=valid_y)\n",
        "test_loss, test_metric = trainer.test(test_X, test_y)\n",
        "print('test_loss:  {:.5f} | test_metric:  {:.5f}'.format(test_loss, test_metric))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/500 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-41551738c7c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nEMBEDDING_DIM = 16\\nLEARNING_RATE = 1e-4\\nREGULARIZATION = 1e-6\\nBATCH_SIZE = 1024\\nEPOCH = 500\\nTRIAL = 100\\n\\nbr = BetaRecommendation(field_dims, EMBEDDING_DIM).to(device)\\n\\noptimizer = optim.Adam(br.parameters(), lr=LEARNING_RATE, weight_decay=REGULARIZATION)\\n# criterion = nn.BCELoss()\\n# criterion = nn.CrossEntropyLoss()\\ncriterion = Beta_Loss(model=br)\\n\\ntrainer = Trainer(br, optimizer, criterion, BATCH_SIZE, task=task)\\ntrainer.train(train_X, train_y, epoch=EPOCH, trials=TRIAL, valid_X=valid_X, valid_y=valid_y)\\ntest_loss, test_metric = trainer.test(test_X, test_y)\\nprint('test_loss:  {:.5f} | test_metric:  {:.5f}'.format(test_loss, test_metric))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/content/utils/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_X, train_y, epoch, trials, valid_X, valid_y)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mb_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-a76a82afcefd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, global_mean)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# distance = self.distance(u_dist, m_dist)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWasserstein_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBu\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-a76a82afcefd>\u001b[0m in \u001b[0;36mWasserstein_distance\u001b[0;34m(self, u_dist, m_dist)\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0;31m# Generate reference points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0mu_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mm_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/beta.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mheads_tails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dirichlet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheads_tails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m_validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 raise ValueError('Value is not broadcastable with batch_shape+event_shape: {} vs {}.'.\n\u001b[0;32m--> 277\u001b[0;31m                                  format(actual_shape, expected_shape))\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0msupport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Value is not broadcastable with batch_shape+event_shape: torch.Size([20, 1]) vs torch.Size([1024, 16])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IgdaxFOdz6v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}