{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BetaRec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCCJwTSQxBcTvnu0cmyvur",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claude9493/DSAA5002/blob/main/notebook/BetaRec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoMa4IzK6Qrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178aeae5-05c9-4b6a-9b4b-7870a713553c"
      },
      "source": [
        "!git clone https://github.com/claude9493/dsaa5002.git\n",
        "!mv ./dsaa5002/dataset/ ./\n",
        "!mv ./dsaa5002/utils/ ./"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'dsaa5002' already exists and is not an empty directory.\n",
            "mv: cannot stat './dsaa5002/dataset/': No such file or directory\n",
            "mv: cannot stat './dsaa5002/utils/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_z1xJHo6WLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625b4a05-37cb-448f-b095-34fad735e0cf"
      },
      "source": [
        "%%time\n",
        "\n",
        "from utils.utils import create_dataset, Trainer\n",
        "# from layer.layer import Embedding, FeaturesEmbedding, EmbeddingsInteraction, MultiLayerPerceptron\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Training on [{}].'.format(device))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on [cuda:0].\n",
            "CPU times: user 907 ms, sys: 377 ms, total: 1.28 s\n",
            "Wall time: 1.17 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5mq1ihz6XqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a07205-e533-4eb0-de5c-ff29d2fbd967"
      },
      "source": [
        "%%time\n",
        "SAMPLE_NUM = 10000\n",
        "task = 'regression'  # 'classification'\n",
        "dataset = create_dataset('movielens', sample_num=SAMPLE_NUM, task=task, device=device)\n",
        "field_dims, (train_X, train_y), (valid_X, valid_y), (test_X, test_y) = dataset.train_valid_test_split()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.69 s, sys: 817 ms, total: 2.5 s\n",
            "Wall time: 2.49 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnCcw77aRwEX"
      },
      "source": [
        "# train_iterator = SingledirectionalOneShotIterator(DataLoader(\n",
        "#     TensorDataset(train_X, train_y),\n",
        "#     # TrainDataset(train_path_queries, nentity, nrelation, args.negative_sample_size, train_answers),\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     shuffle=True\n",
        "#     # num_workers=args.cpu_num\n",
        "#     # collate_fn=TrainDataset.collate_fn\n",
        "# ))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTsF5YWK6ZjW"
      },
      "source": [
        "class SingledirectionalOneShotIterator(object):\n",
        "    def __init__(self, dataloader):\n",
        "        self.iterator = self.one_shot_iterator(dataloader)\n",
        "        self.step = 0\n",
        "        \n",
        "    def __next__(self):\n",
        "        self.step += 1\n",
        "        data = next(self.iterator)\n",
        "        return data\n",
        "    \n",
        "    @staticmethod\n",
        "    def one_shot_iterator(dataloader):\n",
        "        while True:\n",
        "            for data in dataloader:\n",
        "                yield data\n",
        "\n",
        "class Beta_Loss:\n",
        "    def __init__(self, model, reg_biase=0.005, reg_lambda=0.005):\n",
        "        self.reg_biase = reg_biase\n",
        "        self.reg_lambda = reg_lambda\n",
        "        self.model = model\n",
        "\n",
        "    def __call__(self, pred, target):\n",
        "        loss = (1-self.reg_biase) * nn.MSELoss()(pred, torch.squeeze(target))\n",
        "        loss += self.reg_biase * self.model.loss[0]\n",
        "        # loss += self.reg_lambda * self.model.loss[1]\n",
        "        loss = nn.MSELoss(reduction='sum')(pred.view(-1,1), target)\n",
        "        loss = torch.nan_to_num(loss)\n",
        "        # print(pred.view(-1,1), target)\n",
        "        return loss\n",
        "\n",
        "class Regularizer():\n",
        "    def __init__(self, base_add, min_val, max_val):\n",
        "        self.base_add = base_add\n",
        "        self.min_val = min_val\n",
        "        self.max_val = max_val\n",
        "\n",
        "    def __call__(self, entity_embedding):\n",
        "        return torch.clamp(entity_embedding + self.base_add, self.min_val, self.max_val)\n",
        "\n",
        "\n",
        "class BetaRecommendation(nn.Module):\n",
        "\n",
        "    def __init__(self, field_dims, embed_dim=4, **kwargs):\n",
        "        super(BetaRecommendation, self).__init__()\n",
        "        n_users, n_movies = field_dims[0], field_dims[1]\n",
        "\n",
        "        self.gamma = nn.Parameter(\n",
        "            torch.Tensor([kwargs.get('gamma', 12)]), \n",
        "            requires_grad=False\n",
        "        )\n",
        "\n",
        "        self.Bu = nn.Parameter(torch.randn(n_users), requires_grad=True)\n",
        "        self.Bm = nn.Parameter(torch.randn(n_movies), requires_grad=True)\n",
        "\n",
        "        self.u = nn.Embedding(n_users, embed_dim * 2)\n",
        "        # self.u = nn.Parameter(torch.zeros(n_users, embed_dim * 2))\n",
        "        self.m = nn.Embedding(n_movies, embed_dim * 2)\n",
        "        # self.m = nn.Parameter(torch.zeros(n_movies, embed_dim * 2))\n",
        "        \n",
        "        self.u.weight.data.uniform_(0.05, 1e9)\n",
        "        self.m.weight.data.uniform_(0.05, 1e9)\n",
        "        \n",
        "        self.regularizer = Regularizer(1, 0.05, 1e9)\n",
        "        self.loss = [0,0]\n",
        "\n",
        "        \n",
        "    def forward(self, x, global_mean=0):\n",
        "        users, movies = x[:,0], x[:,1]\n",
        "        u, m = self.u(users), self.m(movies)\n",
        "        Bu, Bm = self.Bu[users], self.Bm[movies]\n",
        "        u[torch.isnan(u)] = 0.05\n",
        "        m[torch.isnan(m)] = 0.05\n",
        "\n",
        "        alpha_u, beta_u = torch.chunk(self.regularizer(u), 2, dim=-1)\n",
        "        alpha_m, beta_m = torch.chunk(self.regularizer(m), 2, dim=-1)\n",
        "\n",
        "        u_dist = torch.distributions.beta.Beta(alpha_u, beta_u)\n",
        "        m_dist = torch.distributions.beta.Beta(alpha_m, beta_m)\n",
        "\n",
        "        distance = self.distance(u_dist, m_dist)\n",
        "    \n",
        "        output = Bu + Bm - distance\n",
        "        \n",
        "        self.loss[0] = torch.norm(Bu) + torch.norm(Bm)\n",
        "        # self.loss[1] = torch.norm(u) + torch.norm(m)\n",
        "        return output\n",
        "      \n",
        "    def distance(self, u_dist, m_dist):\n",
        "      # return torch.norm(torch.distributions.kl.kl_divergence(u_dist, m_dist), p=1, dim=-1)\n",
        "      \n",
        "      # print([u_dist, m_dist, \n",
        "            #  torch.norm(torch.nan_to_num(torch.log(torch.distributions.kl.kl_divergence(u_dist, m_dist)), \n",
        "                                        #  nan=1.0, posinf=1.0), p=1, dim=-1)])\n",
        "\n",
        "      return torch.nan_to_num(self.gamma - torch.norm(torch.nan_to_num(torch.log(torch.distributions.kl.kl_divergence(u_dist, m_dist)), \n",
        "                                                                       nan=1, posinf=1), \n",
        "                                                      p=1, dim=-1))\n",
        "      # return torch.norm(torch.pi/2.0 * torch.atan(torch.distributions.kl.kl_divergence(u_dist, m_dist)), p=1, dim=-1)\n",
        "\n",
        "    @staticmethod\n",
        "    def train_step(model, optimizer, train_iterator, args, step):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      x, y = next(train_iterator)\n",
        "      users, movies = x[:,0], x[:,1]\n",
        "\n",
        "      batch_queries_dict = collections.defaultdict(list)\n",
        "      batch_idxs_dict = collections.defaultdict(list)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpXIAm7E6pb-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "62571338-537c-47e8-b0b7-d9fd89f56224"
      },
      "source": [
        "%%time\n",
        "\n",
        "EMBEDDING_DIM = 16\n",
        "LEARNING_RATE = 1e-4\n",
        "REGULARIZATION = 1e-6\n",
        "BATCH_SIZE = 1024\n",
        "EPOCH = 500\n",
        "TRIAL = 100\n",
        "\n",
        "br = BetaRecommendation(field_dims, EMBEDDING_DIM).to(device)\n",
        "\n",
        "optimizer = optim.Adam(br.parameters(), lr=LEARNING_RATE, weight_decay=REGULARIZATION)\n",
        "# criterion = nn.BCELoss()\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = Beta_Loss(model=br)\n",
        "\n",
        "trainer = Trainer(br, optimizer, criterion, BATCH_SIZE, task=task)\n",
        "trainer.train(train_X, train_y, epoch=EPOCH, trials=TRIAL, valid_X=valid_X, valid_y=valid_y)\n",
        "test_loss, test_metric = trainer.test(test_X, test_y)\n",
        "print('test_loss:  {:.5f} | test_metric:  {:.5f}'.format(test_loss, test_metric))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.0 Validation loss: 0.0:  20%|██        | 100/500 [00:09<00:38, 10.51it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 0.00000 | train_metric: -0.00000\n",
            "valid_loss: 0.00000 | valid_metric: -0.00000\n",
            "test_loss:  0.00000 | test_metric:  -0.00000\n",
            "CPU times: user 9.55 s, sys: 192 ms, total: 9.74 s\n",
            "Wall time: 9.83 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IgdaxFOdz6v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}